{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression practical\n",
    "By Dominic Waithe 2018. Updated (2019).\n",
    "\n",
    "This is a Jupyter notebook. Each cell represents a different python script. Variables which are assigned are accessible from all the cells. As as consequence of this, the order and the number of times a cell is run can be important as variables can be changed multiple times.\n",
    "\n",
    "- To run a cell, click the cell and press \"shift-enter\" on your keyboard. Alternatively, click the \">|\" button above or click \"Run\" from the \"Cell\" menu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.80124465]\n",
      " [-0.80124465  1.        ]]\n",
      "corr -0.8012446509407865\n",
      "r2 0.6419929906612227\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Please run this cell you will need it later.\n",
    "#It loads in the functions necessary for this practical.\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#This is a simple numpy implementation of the correlation function.\n",
    "def correlation(data1, data2):\n",
    "    \"data1 & data2 should be numpy arrays.\"\n",
    "    mean1 = data1.mean() \n",
    "    mean2 = data2.mean()\n",
    "    std1 = data1.std()\n",
    "    std2 = data2.std()\n",
    "    corr = ((data1*data2).mean()-mean1*mean2)/(std1*std2)\n",
    "    return corr\n",
    "\n",
    "\n",
    "\n",
    "#Here is some data. [[x0,y0],[x1,y1],[x2,y2],...,[xn,yn]]\n",
    "data = [[18,  510],[20,  590],[22,  560],[23,  510],[23,  460],[25,  490],[27,  560],[28,  510],\n",
    "[29,  460],[32,  410],[37,  420],[41,  460],[46,  450],[49,  380],[53,  460],[55,  420],[63,  350],\n",
    "[65,  420],[66,  300],[67,  410],[68,  300],[70,  390],[71,  320],[72,  370],[73,  280],[74,  420],\n",
    "[75,  460],[77,  360],[79,  310],[82,  360]]\n",
    "x = np.array(data)[:,0]\n",
    "y = np.array(data)[:,1]\n",
    "#How to plot data like this.\n",
    "plt.plot(x,y,'ko')\n",
    "#TODO: calculate the correlation value for this data. Would we apply linear regression on this data?\n",
    "print(np.corrcoef(x,y))\n",
    "corr = correlation(x,y)\n",
    "print('corr',corr)\n",
    "print('r2',corr**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the analytical solution for solving simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.array([[18,  510],[20,  590],[22,  560],[23,  510],[23,  460],[25,  490],[27,  560],[28,  510],\n",
    "[29,  460],[32,  410],[37,  420],[41,  460],[46,  450],[49,  380],[53,  460],[55,  420],[63,  350],\n",
    "[65,  420],[66,  300],[67,  410],[68,  300],[70,  390],[71,  320],[72,  370],[73,  280],[74,  420],\n",
    "[75,  460],[77,  360],[79,  310],[82,  360]])\n",
    "n = data.shape[0]\n",
    "x = data[:,0]\n",
    "y = data[:,1]\n",
    "#Using the expanded equations from the notes.\n",
    "# equation (1).\n",
    "b0 = (np.average(y)*(np.sum(x**2))-np.average(x)*np.sum(x*y))/(np.sum(x**2)-n*np.average(x)**2)\n",
    "print('b0',b0) \n",
    "# equation (2).\n",
    "b1 = ((np.sum(x*y))-n*np.average(x)*np.average(y))/(np.sum(x**2)-n*np.average(x)**2)\n",
    "print('b1',b1)\n",
    "#visualisation\n",
    "xx = np.linspace(np.min(x),np.max(x),2)\n",
    "yy = np.array(b0+ b1 * xx)\n",
    "plt.plot(xx,yy,'-',color='pink')\n",
    "plt.scatter(data[:,0], data[:,1],color='k')\n",
    "plt.title(\"XY plot comparing the independent variable and the dependent variable \")\n",
    "plt.xlabel(\"Independent variable (x)\")\n",
    "plt.ylabel(\"Dependent variable (y)\")\n",
    "#You could do it for higher dimension input data (i.e. 3D or nD data, but the equations get very long!!!!).\n",
    "\n",
    "#TODO: Load the interactive demonstration:\n",
    "#http://userweb.molbiol.ox.ac.uk/dwaithe/WIMM_Advanced_Imaging/linearRegressiond4.html\n",
    "#Can you get the same parameters as the fit. Do you agree with the choice? \n",
    "#Bonus: Calculate the error. Is it the same as in the demonstration? Can you get lower. This is quite challenging so\n",
    "#you can skip this bonus challenge if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the generalisable solution for solving linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.array([[18,  510],[20,  590],[22,  560],[23,  510],[23,  460],[25,  490],[27,  560],[28,  510],\n",
    "[29,  460],[32,  410],[37,  420],[41,  460],[46,  450],[49,  380],[53,  460],[55,  420],[63,  350],\n",
    "[65,  420],[66,  300],[67,  410],[68,  300],[70,  390],[71,  320],[72,  370],[73,  280],[74,  420],\n",
    "[75,  460],[77,  360],[79,  310],[82,  360]])\n",
    "n = data.shape[0]\n",
    "#(X'X) This is equivalent to the matrix [[n,np.sum(x)],[np.sum(x),np.sum(x**2)]]\n",
    "X = np.array([np.ones(n),data[:,0]]).T\n",
    "XtX = X.T.dot(X) #left side of equation (3)\n",
    "#(X'Y) This is equivalent to the matrix [[np.sum(y)],[np.sum(x*y)]]\n",
    "y = np.array(data[:,1])\n",
    "XtY = X.T.dot(y) #right side of equation (4)\n",
    "\n",
    "#This is equation (4) the solve bit does the inversion. It does the hard work!\n",
    "beta = np.linalg.solve(XtX,XtY)\n",
    "#Above can involve a lot of memory if they are high in dimension.\n",
    "\n",
    "#TODO: print the output paramaters and visualise the data.\n",
    "#Should give the same answer as above :-).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more realistic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO. \n",
    "#Download some data and fit it using the linear regression methods above.\n",
    "#e.g. sklearn.datasets.load_diabetes(return_X_y=False)\n",
    "#https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset\n",
    "import sklearn.datasets\n",
    "a = sklearn.datasets.load_diabetes(return_X_y=False)\n",
    "#Just plot two variables at a time.\n",
    "#calculate the correlation for each of the independent variables with respect to the dependent.\n",
    "for num in range(0,a['data'].shape[1]):\n",
    "    print(a['feature_names'][num],'vs dependent',correlation(a['data'][:,num],a['target']))\n",
    "#Find the most correlated and fit a line to it.\n",
    "#measure the correlation\n",
    "#Make a figure, label the axis, and give it a title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher dimension multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#### This is the generalisable solution for solving linear regression.\n",
    "###In this case optimised for 3-D data.\n",
    "\n",
    "#We reformat our data a little bit. Notice where the extra has gone.\n",
    "x_nD = np.array([[1,2,3,4,5,6],[3,7,10,5,4,3]])\n",
    "\n",
    "y = np.array([6,5,7,7,8,9.5])\n",
    "n = y.shape[0]\n",
    "\n",
    "#(X'X) Notice the extra column.\n",
    "X = np.array([np.ones(n),x_nD[0],x_nD[1]]).T\n",
    "XtX = X.T.dot(X)\n",
    "#(X'Y) \n",
    "y = np.array(y)\n",
    "XtY = X.T.dot(y)\n",
    "beta = np.linalg.solve(XtX,XtY)#This does the hard work! \n",
    "#Above can involve a lot of memory if they are high in dimension.\n",
    "\n",
    "#print the paramters of our line.\n",
    "print('b0',beta[0])\n",
    "print('b1',beta[1])\n",
    "print('b2',beta[2])\n",
    "\n",
    "\n",
    "\n",
    "#Visualise the plane which we fit in the case of two independent and one denpendent variables.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(x_nD[0], x_nD[1], y, zdir='z', s=20, c=None, depthshade=True)\n",
    "x = y = np.arange(np.min(x_nD), np.max(x_nD), 0.05)\n",
    "x0, x1 = np.meshgrid(x, y)\n",
    "Z = np.array(beta[0]+ beta[1] * x0 + beta[2]*x1)\n",
    "\n",
    "\n",
    "ax.plot_surface(x0,x1,Z,color='red')\n",
    "plt.title(\"XYZ plot comparing two independent variables and the dependent variable \")\n",
    "plt.xlabel(\"Independent variable (x0)\")\n",
    "plt.ylabel(\"Independent variable (x1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "\n",
    "#Can you see how the above code could be changed to make it work in 4-D or more?\n",
    "#Try and create code which works for dimensions of the  diabetes data. \n",
    "#You won't be able to visualise the output as a graph.\n",
    "\n",
    "\n",
    "#print the parameters of your line.\n",
    "print('b0',beta[0])\n",
    "print('b1',beta[1])\n",
    "print('b2',beta[2])\n",
    "#print('b3',beta[3])\n",
    "#print('b4',beta[4])\n",
    "#print('b5',beta[5])\n",
    "#How can you check if your method is working correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent as an alternative optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import time\n",
    "#How about if we add lots of data now.\n",
    "x_nD = np.array(np.random.random((100000,2)))\n",
    "y = x_nD[:,0]*9.0+x_nD[:,1]\n",
    "SGDRegressor(loss=\"squared_loss\")\n",
    "clf = SGDRegressor()\n",
    "\n",
    "X0 = x_nD[:,0].reshape(1,-1)*5.0  # SGDRegressor is very particular on input \"X\" and insists on a true matrix \n",
    "y0 = y.tolist()\n",
    "\n",
    "t1 = time.time()\n",
    "clf.fit(X0.T,y0)#Stochastic Gradient Descent approach.\n",
    "t0 = time.time()\n",
    "print(t0-t1,\"ms SGD iterative method.\")\n",
    "\n",
    "n = x_nD.shape[0]\n",
    "\n",
    "t1 = time.time()\n",
    "#(X'X) This is equivalent to the matrix [[n,np.sum(x)],[np.sum(x),np.sum(x**2)]]\n",
    "X = np.array([np.ones(n),x_nD[:,0]*5.0]).T\n",
    "XtX = X.T.dot(X)\n",
    "#(X'Y) This is equivalent to the matrix [[np.sum(y)],[np.sum(x*y)]]\n",
    "y = np.array(y0).reshape(-1,1)\n",
    "XtY = X.T.dot(y)\n",
    "beta = np.linalg.solve(XtX,XtY)#Analytical linear algebra approach.\n",
    "t0 = time.time()\n",
    "print(t0-t1,\"ms analytical least squares method.\")\n",
    "#Your previous analytical method can involve a lot of memory if the arrays are very long and high in dimension.\n",
    "#At this size of data however, at low dimension, it is very fast compared SGD.\n",
    "\n",
    "\n",
    "print('b0',clf.intercept_[0],'iterative')\n",
    "print('b1',clf.coef_[0],'iterative')\n",
    "print('b0',beta[0][0],'analytical')\n",
    "print('b1',beta[1][0],'analytical')\n",
    "\n",
    "\n",
    "plt.plot(X0[0],y0,'o')\n",
    "xx = np.linspace(0,5,2)\n",
    "yy = np.array(clf.intercept_+ clf.coef_[0] * xx)\n",
    "plt.plot(xx,yy.T,color='b')\n",
    "yy = np.array(beta[0]+ beta[1] * xx)\n",
    "plt.plot(xx,yy.T,color='r')\n",
    "###Which is faster???\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO. sklearn has a dedicated least squares solver for solving linear regression problems. \n",
    "###Find this function and test it on the above data and your diabetes data. Which method is fastest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
